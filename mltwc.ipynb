{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b8e9bec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from datetime import datetime\n",
    "import tarfile\n",
    "from six.moves import urllib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from zlib import crc32\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from pandas.plotting import scatter_matrix\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.regression import LinearRegression, LinearRegressionModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "511b92a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark.context import SparkContext\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder.getOrCreate()\n",
    "sc = SparkContext.getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "67a2b4ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# download data from csv\n",
    "data = pd.read_csv('2023-01-27_17_10_influxdb_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "38ef7b92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "buzz    45326\n",
       "fill    45326\n",
       "stol    45326\n",
       "Name: _field, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# view existing keys\n",
    "filtered_data = data.drop([\"result\", \"table\", \"_start\", \"_stop\", \"_measurement\", \"key\", \"Unnamed: 0\"], axis=1)\n",
    "filtered_data[\"_field\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e08c6907",
   "metadata": {},
   "outputs": [],
   "source": [
    "# parse keys into seperate dataframes\n",
    "buzz_df = pd.DataFrame([element for element in filtered_data.to_numpy() if element[2] == \"buzz\"])\n",
    "fill_df = pd.DataFrame([element for element in filtered_data.to_numpy() if element[2] == \"fill\"])\n",
    "stol_df = pd.DataFrame([element for element in filtered_data.to_numpy() if element[2] == \"stol\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b7f7f91a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter past and future values for prediction\n",
    "#future_values = [filtered_data['_value'].loc[[int(i[0]+1440)]][i[0]+1440] for i in enumerate(filtered_data.to_numpy()) if i[0] < len(filtered_data['_value']-1440) and i[1][2] == \"fill\"]\n",
    "#dist_past_30m = [filtered_data['_value'].loc[[int(i[0]-1440)]][i[0]-1440] for i in enumerate(filtered_data.to_numpy()) if i[0] > 0 and i[1][2] == \"fill\"]\n",
    "#dist_past_30m.insert(0, dist_past_30m[0])\n",
    "past_values_30m = [filtered_data[\"_value\"].loc[[i[0]-131]][i[0]-131] for i in enumerate(filtered_data.to_numpy()) if i[0]>45326+131 and i[0]<90653]\n",
    "for i in range(0,131):\n",
    "    past_values_30m.insert(0, -1)\n",
    "past_values_2h = [filtered_data[\"_value\"].loc[[i[0]-545]][i[0]-545] for i in enumerate(filtered_data.to_numpy()) if i[0]>45326+545 and i[0]<90653]\n",
    "for i in range(0,545):\n",
    "    past_values_2h.insert(0, -1)\n",
    "past_values_4h = [filtered_data[\"_value\"].loc[[i[0]-1091]][i[0]-1091] for i in enumerate(filtered_data.to_numpy()) if i[0]>45326+1091 and i[0]<90653]\n",
    "for i in range(0,1091):\n",
    "    past_values_4h.insert(0, -1)\n",
    "future_values = [filtered_data[\"_value\"].loc[[i[0]+1091]][i[0]+1091] for i in enumerate(filtered_data.to_numpy()) if i[0]>45326 and i[0]<89561 and i[1][2] == \"fill\"]\n",
    "for i in range(0,1092):\n",
    "    future_values.append(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c1344380",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fill</th>\n",
       "      <th>buzz</th>\n",
       "      <th>fill_future_4h</th>\n",
       "      <th>fill_past_30m</th>\n",
       "      <th>fill_past_2h</th>\n",
       "      <th>fill_past_4h</th>\n",
       "      <th>stol</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>hour</th>\n",
       "      <th>minute</th>\n",
       "      <th>second</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1091</th>\n",
       "      <td>39</td>\n",
       "      <td>0</td>\n",
       "      <td>39</td>\n",
       "      <td>39</td>\n",
       "      <td>39</td>\n",
       "      <td>39</td>\n",
       "      <td>0</td>\n",
       "      <td>2023</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>14</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1092</th>\n",
       "      <td>39</td>\n",
       "      <td>0</td>\n",
       "      <td>39</td>\n",
       "      <td>39</td>\n",
       "      <td>39</td>\n",
       "      <td>39</td>\n",
       "      <td>0</td>\n",
       "      <td>2023</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>14</td>\n",
       "      <td>4</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1093</th>\n",
       "      <td>39</td>\n",
       "      <td>0</td>\n",
       "      <td>39</td>\n",
       "      <td>39</td>\n",
       "      <td>39</td>\n",
       "      <td>39</td>\n",
       "      <td>0</td>\n",
       "      <td>2023</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>14</td>\n",
       "      <td>4</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1094</th>\n",
       "      <td>39</td>\n",
       "      <td>0</td>\n",
       "      <td>39</td>\n",
       "      <td>39</td>\n",
       "      <td>39</td>\n",
       "      <td>39</td>\n",
       "      <td>0</td>\n",
       "      <td>2023</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>14</td>\n",
       "      <td>4</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1095</th>\n",
       "      <td>39</td>\n",
       "      <td>0</td>\n",
       "      <td>39</td>\n",
       "      <td>39</td>\n",
       "      <td>39</td>\n",
       "      <td>39</td>\n",
       "      <td>0</td>\n",
       "      <td>2023</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>14</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44229</th>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>97</td>\n",
       "      <td>22</td>\n",
       "      <td>35</td>\n",
       "      <td>47</td>\n",
       "      <td>0</td>\n",
       "      <td>2023</td>\n",
       "      <td>1</td>\n",
       "      <td>26</td>\n",
       "      <td>8</td>\n",
       "      <td>28</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44230</th>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>97</td>\n",
       "      <td>22</td>\n",
       "      <td>35</td>\n",
       "      <td>47</td>\n",
       "      <td>0</td>\n",
       "      <td>2023</td>\n",
       "      <td>1</td>\n",
       "      <td>26</td>\n",
       "      <td>8</td>\n",
       "      <td>28</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44231</th>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>97</td>\n",
       "      <td>22</td>\n",
       "      <td>35</td>\n",
       "      <td>45</td>\n",
       "      <td>0</td>\n",
       "      <td>2023</td>\n",
       "      <td>1</td>\n",
       "      <td>26</td>\n",
       "      <td>8</td>\n",
       "      <td>28</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44232</th>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>97</td>\n",
       "      <td>22</td>\n",
       "      <td>35</td>\n",
       "      <td>47</td>\n",
       "      <td>0</td>\n",
       "      <td>2023</td>\n",
       "      <td>1</td>\n",
       "      <td>26</td>\n",
       "      <td>8</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44233</th>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>97</td>\n",
       "      <td>22</td>\n",
       "      <td>35</td>\n",
       "      <td>45</td>\n",
       "      <td>0</td>\n",
       "      <td>2023</td>\n",
       "      <td>1</td>\n",
       "      <td>26</td>\n",
       "      <td>8</td>\n",
       "      <td>29</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>42865 rows Ã— 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       fill  buzz  fill_future_4h  fill_past_30m  fill_past_2h  fill_past_4h  \\\n",
       "1091     39     0              39             39            39            39   \n",
       "1092     39     0              39             39            39            39   \n",
       "1093     39     0              39             39            39            39   \n",
       "1094     39     0              39             39            39            39   \n",
       "1095     39     0              39             39            39            39   \n",
       "...     ...   ...             ...            ...           ...           ...   \n",
       "44229    22     0              97             22            35            47   \n",
       "44230    22     0              97             22            35            47   \n",
       "44231    22     0              97             22            35            45   \n",
       "44232    22     0              97             22            35            47   \n",
       "44233    22     0              97             22            35            45   \n",
       "\n",
       "       stol  year  month  day  hour  minute  second  \n",
       "1091      0  2023      1   19    14       4      10  \n",
       "1092      0  2023      1   19    14       4      20  \n",
       "1093      0  2023      1   19    14       4      40  \n",
       "1094      0  2023      1   19    14       4      50  \n",
       "1095      0  2023      1   19    14       5       0  \n",
       "...     ...   ...    ...  ...   ...     ...     ...  \n",
       "44229     0  2023      1   26     8      28      20  \n",
       "44230     0  2023      1   26     8      28      40  \n",
       "44231     0  2023      1   26     8      28      50  \n",
       "44232     0  2023      1   26     8      29       0  \n",
       "44233     0  2023      1   26     8      29      30  \n",
       "\n",
       "[42865 rows x 13 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# merge dataframe for use in spark\n",
    "temp_all_rows = pd.merge(fill_df, buzz_df, how='inner', on=0)\n",
    "temp_all_rows[\"fill_future_4h\"] = future_values\n",
    "temp_all_rows[\"fill_past_30m\"] = past_values_30m\n",
    "temp_all_rows[\"fill_past_2h\"] = past_values_2h\n",
    "temp_all_rows[\"fill_past_4h\"] = past_values_4h\n",
    "all_rows = pd.merge(temp_all_rows, stol_df, how='inner', on=0)\n",
    "renamed_rows = all_rows.rename(columns={'1_x': 'fill', '1_y': 'buzz', 1: 'stol', 0: 'tod'})\n",
    "pandas_df = renamed_rows.drop(['2_x', '2_y', 2], axis=1)\n",
    "pandas_df[\"tod\"] = [datetime.strptime(row, '%Y-%m-%dT%H:%M:%S') for row in [row.split('Z')[0] for row in [row.split('.')[0] for row in pandas_df[\"tod\"]]]]\n",
    "pandas_df[\"year\"] = [date.year for date in pandas_df[\"tod\"]]\n",
    "pandas_df[\"month\"] = [date.month for date in pandas_df[\"tod\"]]\n",
    "pandas_df[\"day\"] = [date.day for date in pandas_df[\"tod\"]]\n",
    "pandas_df[\"hour\"] = [date.hour for date in pandas_df[\"tod\"]]\n",
    "pandas_df[\"minute\"] = [date.minute for date in pandas_df[\"tod\"]]\n",
    "pandas_df[\"second\"] = [date.second for date in pandas_df[\"tod\"]]\n",
    "pandas_df = pandas_df.drop(['tod'], axis=1)\n",
    "pandas_df = pandas_df.drop(pandas_df[pandas_df.fill_future_4h < 0].index)\n",
    "pandas_df = pandas_df.drop(pandas_df[pandas_df.fill_past_4h < 0].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "819b3277",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create spark dataframe\n",
    "sparkDF=spark.createDataFrame(pandas_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "765dd804",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('fill', 'bigint'),\n",
       " ('buzz', 'bigint'),\n",
       " ('fill_future_4h', 'bigint'),\n",
       " ('fill_past_30m', 'bigint'),\n",
       " ('fill_past_2h', 'bigint'),\n",
       " ('fill_past_4h', 'bigint'),\n",
       " ('stol', 'bigint'),\n",
       " ('year', 'bigint'),\n",
       " ('month', 'bigint'),\n",
       " ('day', 'bigint'),\n",
       " ('hour', 'bigint'),\n",
       " ('minute', 'bigint'),\n",
       " ('second', 'bigint')]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# view spark types (only number types allowed)\n",
    "sparkDF.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8114f771",
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify feature columns to prepare for ML\n",
    "feature_cols = ['year', 'month', 'day', 'hour', 'minute', 'second', 'fill', 'buzz', 'stol', 'fill_past_30m', 'fill_past_2h', 'fill_past_4h']\n",
    "\n",
    "vect_assembler = VectorAssembler(inputCols = feature_cols, outputCol = \"features\")\n",
    "\n",
    "data_w_features = vect_assembler.transform(sparkDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c04a4d6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify output column\n",
    "data_for_training = data_w_features.select('features', 'fill_future_4h')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e81a4992",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train-test-split\n",
    "train_dataset, test_dataset = data_for_training.randomSplit([0.7, 0.3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4c9d0755",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------+------------------+\n",
      "|            features|fill_future_4h|        prediction|\n",
      "+--------------------+--------------+------------------+\n",
      "|[2023.0,1.0,19.0,...|            39| 52.13295376805202|\n",
      "|[2023.0,1.0,19.0,...|            39| 52.14657228475502|\n",
      "|[2023.0,1.0,19.0,...|            39| 52.15338154310652|\n",
      "|[2023.0,1.0,19.0,...|            39| 52.11724556106994|\n",
      "|[2023.0,1.0,19.0,...|            39|52.121965129142374|\n",
      "|[2023.0,1.0,19.0,...|            39| 52.09944766380881|\n",
      "|[2023.0,1.0,19.0,...|            39|52.083739456826734|\n",
      "|[2023.0,1.0,19.0,...|            39| 52.23379603517424|\n",
      "|[2023.0,1.0,19.0,...|            39|  52.0659415595656|\n",
      "|[2023.0,1.0,19.0,...|            39| 52.23851560324667|\n",
      "|[2023.0,1.0,19.0,...|            39|  52.2228073962646|\n",
      "|[2023.0,1.0,19.0,...|            39|52.229616654616095|\n",
      "|[2023.0,1.0,19.0,...|            39| 52.20028993093103|\n",
      "|[2023.0,1.0,19.0,...|            39| 52.21390844763403|\n",
      "|[2023.0,1.0,19.0,...|            39| 52.19139098230046|\n",
      "|[2023.0,1.0,19.0,...|            39| 52.18249203366989|\n",
      "|[2023.0,1.0,19.0,...|            39| 52.19611055037289|\n",
      "|[2023.0,1.0,19.0,...|            39| 52.20972906707589|\n",
      "|[2023.0,1.0,19.0,...|            39|52.200830118445325|\n",
      "|[2023.0,1.0,19.0,...|            39| 52.17831265311176|\n",
      "+--------------------+--------------+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# train model\n",
    "LinReg = LinearRegression(featuresCol = \"features\", labelCol = \"fill_future_4h\")\n",
    "\n",
    "# Train the model on the training using fit() method.\n",
    "model = LinReg.fit(train_dataset)\n",
    "\n",
    "# Predict the Grades using the evulate method\n",
    "pred = model.evaluate(test_dataset)\n",
    "\n",
    "#pred.predictions.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7dfa8309",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 11.865\n",
      "MAE: 7.892\n",
      "r2: 0.638\n"
     ]
    }
   ],
   "source": [
    "#evaluate predictions\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "\n",
    "evaluation = RegressionEvaluator(labelCol=\"fill_future_4h\", predictionCol=\"prediction\")\n",
    "rmse = evaluation.evaluate(pred.predictions, {evaluation.metricName: \"rmse\"})\n",
    "#print(\"RMSE: %.3f\" % rmse)\n",
    "mae = evaluation.evaluate(pred.predictions, {evaluation.metricName: \"mae\"})\n",
    "#print(\"MAE: %.3f\" % mae)\n",
    "r2 = evaluation.evaluate(pred.predictions, {evaluation.metricName: \"r2\"})\n",
    "#print(\"r2: %.3f\" %r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "de696c7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# using it for detection\n",
    "#model.write().overwrite().save('./models/')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5592cbf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model_copy = LinearRegressionModel.load('./models/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "13dd3741",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pyspark.ml.regression.LinearRegressionModel'>\n"
     ]
    }
   ],
   "source": [
    "#print(type(model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "81ae8232",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------+------------------+\n",
      "|            features|fill_future_4h|        prediction|\n",
      "+--------------------+--------------+------------------+\n",
      "|[2023.0,1.0,19.0,...|            39| 52.13295376805202|\n",
      "|[2023.0,1.0,19.0,...|            39| 52.14657228475502|\n",
      "|[2023.0,1.0,19.0,...|            39| 52.15338154310652|\n",
      "|[2023.0,1.0,19.0,...|            39| 52.11724556106994|\n",
      "|[2023.0,1.0,19.0,...|            39|52.121965129142374|\n",
      "|[2023.0,1.0,19.0,...|            39| 52.09944766380881|\n",
      "|[2023.0,1.0,19.0,...|            39|52.083739456826734|\n",
      "|[2023.0,1.0,19.0,...|            39| 52.23379603517424|\n",
      "|[2023.0,1.0,19.0,...|            39|  52.0659415595656|\n",
      "|[2023.0,1.0,19.0,...|            39| 52.23851560324667|\n",
      "|[2023.0,1.0,19.0,...|            39|  52.2228073962646|\n",
      "|[2023.0,1.0,19.0,...|            39|52.229616654616095|\n",
      "|[2023.0,1.0,19.0,...|            39| 52.20028993093103|\n",
      "|[2023.0,1.0,19.0,...|            39| 52.21390844763403|\n",
      "|[2023.0,1.0,19.0,...|            39| 52.19139098230046|\n",
      "|[2023.0,1.0,19.0,...|            39| 52.18249203366989|\n",
      "|[2023.0,1.0,19.0,...|            39| 52.19611055037289|\n",
      "|[2023.0,1.0,19.0,...|            39| 52.20972906707589|\n",
      "|[2023.0,1.0,19.0,...|            39|52.200830118445325|\n",
      "|[2023.0,1.0,19.0,...|            39| 52.17831265311176|\n",
      "+--------------------+--------------+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#pred2 = model_copy.evaluate(test_dataset)\n",
    "#pred2.predictions.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "416adb10",
   "metadata": {},
   "outputs": [],
   "source": [
    "#test_dataset.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "3115fc12",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predictFillLevel(current, buzz, stol, last_30m, last_2h, last_4h):\n",
    "    data = [{\"year\": datetime.now().year, \"month\": datetime.now().month, \"day\": datetime.now().day, \"hour\": datetime.now().hour, \"minute\": datetime.now().minute, \"second\": datetime.now().second, \"fill\": current, \"buzz\": buzz , \"stol\": stol, \"fill_past_30m\": last_30m, \"fill_past_2h\": last_2h, \"fill_past_4h\": last_4h, \"fill_future_4h\":-1}]\n",
    "    spark_data = spark.createDataFrame(data)\n",
    "    feature_cols = ['year', 'month', 'day', 'hour', 'minute', 'second', 'fill', 'buzz', 'stol', 'fill_past_30m', 'fill_past_2h', 'fill_past_4h']\n",
    "    vect_assembler = VectorAssembler(inputCols = feature_cols, outputCol = \"features\")\n",
    "    data_w_features = vect_assembler.transform(spark_data)\n",
    "    data_for_training = data_w_features.select('features', 'fill_future_4h')\n",
    "    pred = model.evaluate(data_for_training)\n",
    "    filtered_preds = pred.predictions.drop(\"fill_future_4h\")\n",
    "    filtered_preds.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "32199757",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----------------+\n",
      "|            features|       prediction|\n",
      "+--------------------+-----------------+\n",
      "|[2023.0,1.0,29.0,...|1.313549944846848|\n",
      "+--------------------+-----------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "Exception happened during processing of request from ('127.0.0.1', 37616)\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.8/socketserver.py\", line 316, in _handle_request_noblock\n",
      "    self.process_request(request, client_address)\n",
      "  File \"/opt/conda/lib/python3.8/socketserver.py\", line 347, in process_request\n",
      "    self.finish_request(request, client_address)\n",
      "  File \"/opt/conda/lib/python3.8/socketserver.py\", line 360, in finish_request\n",
      "    self.RequestHandlerClass(request, client_address, self)\n",
      "  File \"/opt/conda/lib/python3.8/socketserver.py\", line 720, in __init__\n",
      "    self.handle()\n",
      "  File \"/usr/local/spark/python/pyspark/accumulators.py\", line 262, in handle\n",
      "    poll(accum_updates)\n",
      "  File \"/usr/local/spark/python/pyspark/accumulators.py\", line 235, in poll\n",
      "    if func():\n",
      "  File \"/usr/local/spark/python/pyspark/accumulators.py\", line 239, in accum_updates\n",
      "    num_updates = read_int(self.rfile)\n",
      "  File \"/usr/local/spark/python/pyspark/serializers.py\", line 564, in read_int\n",
      "    raise EOFError\n",
      "EOFError\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "#predictFillLevel(12, 0, 0, 12, 12, 12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "aff88453",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [{\"year\": 2023, \"month\": 1, \"day\": 27, \"hour\": 10, \"minute\": 10, \"second\": 1, \"fill\": 30, \"buzz\": 0 , \"stol\": 0, \"fill_past_30m\": 30, \"fill_past_2h\": 30, \"fill_past_4h\": 30, \"fill_future_4h\":0}]\n",
    "spark_data = spark.createDataFrame(data)\n",
    "#'year', 'month', 'day', 'hour', 'minute', 'second', 'fill', 'buzz', 'stol', 'fill_past_30m', 'fill_past_2h', 'fill_past_4h']\n",
    "feature_cols = ['year', 'month', 'day', 'hour', 'minute', 'second', 'fill', 'buzz', 'stol', 'fill_past_30m', 'fill_past_2h', 'fill_past_4h']\n",
    "\n",
    "vect_assembler = VectorAssembler(inputCols = feature_cols, outputCol = \"features\")\n",
    "\n",
    "data_w_features = vect_assembler.transform(spark_data)\n",
    "\n",
    "data_for_training = data_w_features.select('features', 'fill_future_4h')\n",
    "pred = model.evaluate(data_for_training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "76e7f447",
   "metadata": {},
   "outputs": [
    {
     "ename": "Py4JJavaError",
     "evalue": "An error occurred while calling z:org.apache.spark.ml.python.MLSerDe.loads.\n: net.razorvine.pickle.PickleException: expected zero arguments for construction of ClassDict (for numpy.dtype)\n\tat net.razorvine.pickle.objects.ClassDictConstructor.construct(ClassDictConstructor.java:23)\n\tat net.razorvine.pickle.Unpickler.load_reduce(Unpickler.java:773)\n\tat net.razorvine.pickle.Unpickler.dispatch(Unpickler.java:213)\n\tat net.razorvine.pickle.Unpickler.load(Unpickler.java:123)\n\tat net.razorvine.pickle.Unpickler.loads(Unpickler.java:136)\n\tat org.apache.spark.mllib.api.python.SerDeBase.loads(PythonMLLibAPI.scala:1322)\n\tat org.apache.spark.ml.python.MLSerDe.loads(MLSerDe.scala)\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.base/java.lang.reflect.Method.invoke(Method.java:566)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPy4JJavaError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-59-7213770438e9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0.0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/spark/python/pyspark/ml/wrapper.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, value)\u001b[0m\n\u001b[1;32m    414\u001b[0m         \u001b[0mPredict\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mgiven\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    415\u001b[0m         \"\"\"\n\u001b[0;32m--> 416\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_java\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"predict\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/spark/python/pyspark/ml/wrapper.py\u001b[0m in \u001b[0;36m_call_java\u001b[0;34m(self, name, *args)\u001b[0m\n\u001b[1;32m     51\u001b[0m         \u001b[0mm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_java_obj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m         \u001b[0msc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSparkContext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_active_spark_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m         \u001b[0mjava_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0m_py2java\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_java2py\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mjava_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/spark/python/pyspark/ml/wrapper.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     51\u001b[0m         \u001b[0mm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_java_obj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m         \u001b[0msc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSparkContext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_active_spark_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m         \u001b[0mjava_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0m_py2java\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_java2py\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mjava_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/spark/python/pyspark/ml/common.py\u001b[0m in \u001b[0;36m_py2java\u001b[0;34m(sc, obj)\u001b[0m\n\u001b[1;32m     79\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbytearray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mPickleSerializer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdumps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 81\u001b[0;31m         \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jvm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0morg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mspark\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMLSerDe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     82\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1302\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1303\u001b[0m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1304\u001b[0;31m         return_value = get_return_value(\n\u001b[0m\u001b[1;32m   1305\u001b[0m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[1;32m   1306\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/spark/python/pyspark/sql/utils.py\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    109\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdeco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 111\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    112\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mpy4j\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprotocol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPy4JJavaError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m             \u001b[0mconverted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconvert_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjava_exception\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/spark/python/lib/py4j-0.10.9-src.zip/py4j/protocol.py\u001b[0m in \u001b[0;36mget_return_value\u001b[0;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[1;32m    324\u001b[0m             \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mOUTPUT_CONVERTER\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0manswer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgateway_client\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    325\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0manswer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mREFERENCE_TYPE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 326\u001b[0;31m                 raise Py4JJavaError(\n\u001b[0m\u001b[1;32m    327\u001b[0m                     \u001b[0;34m\"An error occurred while calling {0}{1}{2}.\\n\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    328\u001b[0m                     format(target_id, \".\", name), value)\n",
      "\u001b[0;31mPy4JJavaError\u001b[0m: An error occurred while calling z:org.apache.spark.ml.python.MLSerDe.loads.\n: net.razorvine.pickle.PickleException: expected zero arguments for construction of ClassDict (for numpy.dtype)\n\tat net.razorvine.pickle.objects.ClassDictConstructor.construct(ClassDictConstructor.java:23)\n\tat net.razorvine.pickle.Unpickler.load_reduce(Unpickler.java:773)\n\tat net.razorvine.pickle.Unpickler.dispatch(Unpickler.java:213)\n\tat net.razorvine.pickle.Unpickler.load(Unpickler.java:123)\n\tat net.razorvine.pickle.Unpickler.loads(Unpickler.java:136)\n\tat org.apache.spark.mllib.api.python.SerDeBase.loads(PythonMLLibAPI.scala:1322)\n\tat org.apache.spark.ml.python.MLSerDe.loads(MLSerDe.scala)\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.base/java.lang.reflect.Method.invoke(Method.java:566)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n\tat java.base/java.lang.Thread.run(Thread.java:829)\n"
     ]
    }
   ],
   "source": [
    "#model.predict(np.array([0.0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba3b1244",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "v_": [
   "dGlsbHRyaXMyMA==",
   "dGlsbHRyaXMyMA=="
  ]
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
